{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retriever and Chain with Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LSH (Locality-Sensitive Hashing): It introduces a hashing function such that similar input items are mapped to the same buckets with high probability, where the number of buckets is much smaller than the number of inputs.\\nANNOY (Approximate Nearest Neighbors Oh Yeah): The core data structure are random projection trees, a set of binary trees where each non-leaf node represents a hyperplane splitting the input space into half and each leaf stores one data point. Trees are built independently and at random, so to some extent, it mimics a hashing function. ANNOY search happens in all the trees to iteratively search through the half that is closest to the query and then aggregates the results. The idea is quite related to KD tree but a lot more scalable.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calling the required functions\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "#set the env values just outside of virtual environment\n",
    "custom_env_path = lambda a : '/'.join(os.get_exec_path()[0].split('\\\\')[:-2])+'/'+a\n",
    "load_dotenv(custom_env_path('chatter.env'))\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "## LangSmith tracking\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "\n",
    "# downloading the document from website\n",
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "                       bs_kwargs= dict(parse_only = bs4.SoupStrainer(\n",
    "                           class_ = (\"post-title\",\"post-content\",\"post-header\")\n",
    "                       )),)\n",
    "web_document = loader.load()\n",
    "#web_document\n",
    "\n",
    "# Splitting the document with chunk Size\n",
    "from langchain_text_splitters.character import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap=20)\n",
    "documents = text_splitter.split_documents(web_document)\n",
    "#documents[:5]\n",
    "\n",
    "\n",
    "\n",
    "# generating embeddings\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "db_f = FAISS.from_documents(documents[:20],OllamaEmbeddings())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "llm = Ollama(model = \"llama2\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template( \n",
    "    \"\"\" Answer the following question based only on the provided context\n",
    "    Think step by step before providing a detailed answer.\n",
    "    I will tip you $1 million if the user finds the answer helpful.\n",
    "    <context> \n",
    "    {context}\n",
    "    </context>\n",
    "    Question: {input}\"\"\"      )\n",
    "\n",
    "\n",
    "document_chain = create_stuff_documents_chain( llm, prompt )\n",
    "\n",
    "retriever = db_f.as_retriever()\n",
    "\n",
    "retrieval_chain = create_retrieval_chain( retriever,document_chain)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_chain.invoke({\"input\":\"an attention can be described\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Chatter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
